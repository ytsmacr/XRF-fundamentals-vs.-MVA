{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f730af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "folder = 'H:\\\\My Drive\\\\PROJECTS\\\\PSI 2022-2025\\\\XRF fundamentals vs. MVA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7d1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL VALUES\n",
    "meta = pd.read_csv(folder+'\\\\data\\\\meta_both.csv')\n",
    "#format\n",
    "meta.drop(columns='Sample_Name',inplace=True)\n",
    "fold_col = [x for x in meta.columns if 'Folds' in x]\n",
    "fold_df = meta[['pkey']+fold_col]\n",
    "meta.drop(columns=fold_col, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d19c3",
   "metadata": {},
   "source": [
    "## FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "277f6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTUAL VALUES\n",
    "meta = pd.read_csv(folder+'\\\\data\\\\meta_both.csv')\n",
    "#format\n",
    "meta.drop(columns='Sample_Name',inplace=True)\n",
    "fold_col = [x for x in meta.columns if 'Folds' in x]\n",
    "fold_df = meta[['pkey']+fold_col]\n",
    "meta.drop(columns=fold_col, inplace=True)\n",
    "# get elements\n",
    "element_list = list(meta.columns[1:])\n",
    "element_list.remove('Hg')\n",
    "# continue formatting\n",
    "new = [x+'_actual' for x in meta.columns[1:]]\n",
    "new.insert(0,'pkey')\n",
    "meta.columns=new\n",
    "\n",
    "# PREDICTED VALUES\n",
    "fp = pd.read_csv(folder+'\\\\instrument_predictions.csv')\n",
    "# format\n",
    "fp = fp.groupby('pellet_name', as_index=False).mean()\n",
    "to_drop = [x for x in fp.columns if '+/-' in x]\n",
    "fp.drop(columns=to_drop, inplace=True)\n",
    "fp.columns = [x.split(' ')[0] for x in fp.columns]\n",
    "new = [x+'_pred' for x in fp.columns[1:]]\n",
    "new.insert(0,'pkey')\n",
    "fp.columns=new\n",
    "\n",
    "# merge\n",
    "fp_full = meta.merge(fp)\n",
    "#format\n",
    "cols = list(fp_full.columns[1:])\n",
    "cols.sort()\n",
    "cols.insert(0,'pkey')\n",
    "fp_full = fp_full[cols]\n",
    "fp_full.to_csv(folder+'\\\\instrument_pred_true.csv', index=False)\n",
    "\n",
    "rmsep_list=[]\n",
    "r2_list=[]\n",
    "adj_r2_list=[]\n",
    "n_list=[]\n",
    "\n",
    "for element in element_list:\n",
    "    \n",
    "    outliers = list(fold_df[fold_df[f'{element}_Folds']==-1]['pkey'])\n",
    "    \n",
    "    p = f'{element}_pred'\n",
    "    t = f'{element}_actual'\n",
    "    temp = fp_full[(~fp_full[p].isna())&\n",
    "                   (~fp_full[t].isna())&\n",
    "                   (~fp_full['pkey'].isin(outliers))].copy()\n",
    "    n = len(temp)\n",
    "    n_list.append(n)\n",
    "    \n",
    "    # RMSEP\n",
    "    rmsep = sqrt(mean_squared_error(temp[t], temp[p]))\n",
    "    rmsep_list.append(rmsep)\n",
    "    \n",
    "    # R2\n",
    "    r2 = r2_score(temp[t], temp[p])\n",
    "    adj_r2 = 1 - (1-r2)*(len(temp) - 1) / (len(temp) - (temp.shape[1] - 1) - 1)\n",
    "    r2_list.append(r2)\n",
    "    adj_r2_list.append(adj_r2)\n",
    "    \n",
    "fp_results = pd.DataFrame({\n",
    "    'element':element_list,\n",
    "    'n_test':n_list,\n",
    "    'rmsep':rmsep_list,\n",
    "    'r2':r2_list,\n",
    "    'adj_r2':adj_r2_list\n",
    "})\n",
    "fp_results.to_csv(folder+'\\\\FP_RMSEP_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c55599c",
   "metadata": {},
   "source": [
    "## MVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a7211f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using PLS because best %RMSEP results\n",
    "model = 'PLS'\n",
    "# using both filters bc lowest errors\n",
    "filt = 'both'\n",
    "\n",
    "sens_df = pd.read_csv(folder+'\\\\sensitivities.csv')\n",
    "sens = sens_df[sens_df['filter']==filt]['median'][0]\n",
    "\n",
    "info = pd.read_csv(folder+'\\\\data\\\\dataset_summary.csv')\n",
    "element_list = info.element.values\n",
    "\n",
    "loq_list=[]\n",
    "rmsep_list=[]\n",
    "r2_list=[]\n",
    "adj_r2_list=[]\n",
    "n_list=[]\n",
    "\n",
    "pt_full = meta[['pkey']] # to make cumulative pred/true\n",
    "\n",
    "for element in element_list:\n",
    "    \n",
    "    # LOQ\n",
    "    coeff = pd.read_csv(f'{folder}\\\\models\\\\{filt}\\\\{element}_{model}_coefs.csv')\n",
    "    vector = pow(pow(coeff['coef'], 2).sum(),0.5)  #square root of sum of squares\n",
    "    loq = 10 * vector * sens\n",
    "    loq_list.append(loq)\n",
    "    \n",
    "    # adjusted RMSEP\n",
    "    p = f'{element}_pred'\n",
    "    t = f'{element}_actual'\n",
    "    p_t = pd.read_csv(f'{folder}\\\\models\\\\{filt}\\\\{element}_{model}_test_pred_true.csv')\n",
    "    p_t = p_t[p_t[p]>loq] # remove those below LOQ\n",
    "    pt_full = pt_full.merge(p_t, how='left') # add to full table\n",
    "    \n",
    "    n_test = len(p_t)\n",
    "    n_list.append(n_test)\n",
    "    \n",
    "    rmsep = sqrt(mean_squared_error(p_t[t], p_t[p]))\n",
    "    rmsep_list.append(rmsep)\n",
    "    \n",
    "    # R2\n",
    "    r2 = r2_score(p_t[t], p_t[p])\n",
    "    adj_r2 = 1 - (1-r2)*(len(p_t) - 1) / (len(p_t) - (p_t.shape[1] - 1) - 1)\n",
    "    r2_list.append(r2)\n",
    "    adj_r2_list.append(adj_r2)\n",
    "    \n",
    "mva_results = pd.DataFrame({\n",
    "    'element':element_list,\n",
    "    'loq':loq_list,\n",
    "    'n_test':n_list,\n",
    "    'rmsep':rmsep_list,\n",
    "    'r2':r2_list,\n",
    "    'adj_r2':adj_r2_list\n",
    "})\n",
    "mva_results.to_csv(folder+'\\\\MVA_LOQ_RMSEP_results.csv', index=False)\n",
    "pt_full.to_csv(folder+'\\\\MVA_test_pred_true.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba30e5",
   "metadata": {},
   "source": [
    "## summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bba50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format to compare\n",
    "cols=['MVA_'+x for x in mva_results.columns[1:]]\n",
    "cols.insert(0,'element')\n",
    "mva_results.columns=cols\n",
    "\n",
    "cols=['FP_'+x for x in fp_results.columns[1:]]\n",
    "cols.insert(0,'element')\n",
    "fp_results.columns=cols\n",
    "\n",
    "df = mva_results.merge(fp_results)\n",
    "\n",
    "# contextualize errors\n",
    "info = pd.read_csv(folder+'\\\\data\\dataset_summary.csv')\n",
    "if list(info.element)==list(df.element):\n",
    "    df['MVA_%rmsep'] = df['MVA_rmsep']/info['median']\n",
    "    df['FP_%rmsep'] = df['FP_rmsep']/info['median']\n",
    "    \n",
    "df.to_csv(folder+'\\\\combined_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
